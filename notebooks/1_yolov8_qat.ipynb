{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLOv8 Modified for QAT Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.48 üöÄ Python-3.9.19 torch-2.3.1+cu118 CUDA:0 (NVIDIA GeForce RTX 4070 SUPER, 12281MiB)\n",
      "Setup complete ‚úÖ (8 CPUs, 15.6 GB RAM, 92.8/250.9 GB disk)\n",
      "/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry\n"
     ]
    }
   ],
   "source": [
    "import ultralytics\n",
    "import os\n",
    "\n",
    "ultralytics.checks()\n",
    "print(os.getcwd())\n",
    "\n",
    "CURRENT_DIR = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install TensorRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.ngc.nvidia.com\n",
      "Collecting nvidia-tensorrt\n",
      "  Downloading https://developer.download.nvidia.com/compute/redist/nvidia-tensorrt/nvidia_tensorrt-8.4.3.1-cp39-none-linux_x86_64.whl (340.9 MB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m340.9/340.9 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: nvidia-cuda-runtime-cu11 in /home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages (from nvidia-tensorrt) (11.8.89)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11 in /home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages (from nvidia-tensorrt) (8.7.0.84)\n",
      "Requirement already satisfied: nvidia-cublas-cu11 in /home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages (from nvidia-tensorrt) (11.11.3.6)\n",
      "Installing collected packages: nvidia-tensorrt\n",
      "Successfully installed nvidia-tensorrt-8.4.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --no-cache nvidia-tensorrt --index-url https://pypi.ngc.nvidia.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download and Copy Necessary Files\n",
    "\n",
    "- `yolov8n.pt` from [https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt)\n",
    "- Copy, \n",
    "    - `trainer.py` from üìÅ `ultralytics-qat` to the `./ultralytics/ultralytics/engine`\n",
    "    - `validator.py` from üìÅ `ultralytics-qat` to the `./ultralytics/ultralytics/engine`\n",
    "    - `default.py` from üìÅ `ultralytics-qat` to the `./ultralytics/ultralytics/cfg`\n",
    "    - `train.py` from üìÅ `ultralytics-qat` to the `./ultralytics`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -fsSL -o ./yolov8n.pt https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicate the original trainer.py, validator.py and default.yaml\n",
    "# !cp ./ultralytics/engine/trainer.py ./ultralytics/engine/trainer_original.py\n",
    "# !cp ./ultralytics/engine/validator.py ./ultralytics/engine/validator_original.py\n",
    "# !cp ./ultralytics/cfg/default.yaml ./ultralytics/cfg/default_original.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the new trainer.py, validator.py and default.yaml\n",
    "!cp /home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat/trainer.py ./ultralytics/engine/\n",
    "!cp /home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat/validator.py ./ultralytics/engine/\n",
    "!cp /home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat/default.yaml ./ultralytics/cfg/\n",
    "!cp /home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat/train.py ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QAT copy directory\n",
    "# !mkdir -p ./ultralytics/engine/QAT\n",
    "# !cp -r /home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat/QAT/* ./ultralytics/engine/QAT/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Upgrade necessary wheel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages (24.1.1)\n",
      "Collecting wheel\n",
      "  Using cached wheel-0.43.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Using cached wheel-0.43.0-py3-none-any.whl (65 kB)\n",
      "Installing collected packages: wheel\n",
      "Successfully installed wheel-0.43.0\n",
      "Collecting nvidia-pyindex\n",
      "  Downloading nvidia-pyindex-1.0.9.tar.gz (10 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: nvidia-pyindex\n",
      "  Building wheel for nvidia-pyindex (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for nvidia-pyindex: filename=nvidia_pyindex-1.0.9-py3-none-any.whl size=8416 sha256=64122a66507dc676bc084450fd49bcc3f176f7e2ff33edae42425e9df35ed406\n",
      "  Stored in directory: /home/jeffrymahbuubi/.cache/pip/wheels/39/63/71/c50214b560fa8c319598c2de3c1616f6d68e1d2c7f17a5e82d\n",
      "Successfully built nvidia-pyindex\n",
      "Installing collected packages: nvidia-pyindex\n",
      "Successfully installed nvidia-pyindex-1.0.9\n",
      "--2024-07-03 15:05:34--  https://developer.download.nvidia.com/compute/redist/onnx-graphsurgeon/onnx_graphsurgeon-0.3.27-py2.py3-none-any.whl\n",
      "Resolving developer.download.nvidia.com (developer.download.nvidia.com)... 152.199.39.144\n",
      "Connecting to developer.download.nvidia.com (developer.download.nvidia.com)|152.199.39.144|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 42150 (41K) [application/octet-stream]\n",
      "Saving to: ‚Äòonnx_graphsurgeon-0.3.27-py2.py3-none-any.whl‚Äô\n",
      "\n",
      "onnx_graphsurgeon-0 100%[===================>]  41.16K  --.-KB/s    in 0.008s  \n",
      "\n",
      "2024-07-03 15:05:34 (5.24 MB/s) - ‚Äòonnx_graphsurgeon-0.3.27-py2.py3-none-any.whl‚Äô saved [42150/42150]\n",
      "\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Processing ./onnx_graphsurgeon-0.3.27-py2.py3-none-any.whl\n",
      "Requirement already satisfied: numpy in /home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages (from onnx-graphsurgeon==0.3.27) (1.26.3)\n",
      "Collecting onnx (from onnx-graphsurgeon==0.3.27)\n",
      "  Downloading onnx-1.16.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
      "Collecting protobuf>=3.20.2 (from onnx->onnx-graphsurgeon==0.3.27)\n",
      "  Downloading protobuf-5.27.2-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Downloading onnx-1.16.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-5.27.2-cp38-abi3-manylinux2014_x86_64.whl (309 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m309.3/309.3 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: protobuf, onnx, onnx-graphsurgeon\n",
      "Successfully installed onnx-1.16.1 onnx-graphsurgeon-0.3.27 protobuf-5.27.2\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pip install --upgrade pip wheel\n",
    "!pip install nvidia-pyindex\n",
    "!wget https://developer.download.nvidia.com/compute/redist/onnx-graphsurgeon/onnx_graphsurgeon-0.3.27-py2.py3-none-any.whl\n",
    "!pip install ./onnx_graphsurgeon-0.3.27-py2.py3-none-any.whl\n",
    "%rm ./onnx_graphsurgeon-0.3.27-py2.py3-none-any*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Install `pytorch-quantization`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting pytorch-quantization==2.1.3\n",
      "  Downloading pytorch_quantization-2.1.3-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: numpy in /home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages (from pytorch-quantization==2.1.3) (1.26.3)\n",
      "Collecting absl-py>=0.7.0 (from pytorch-quantization==2.1.3)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: scipy in /home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages (from pytorch-quantization==2.1.3) (1.13.1)\n",
      "Collecting sphinx-glpi-theme (from pytorch-quantization==2.1.3)\n",
      "  Downloading sphinx_glpi_theme-0.6-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting prettytable (from pytorch-quantization==2.1.3)\n",
      "  Downloading prettytable-3.10.0-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: pyyaml in /home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages (from pytorch-quantization==2.1.3) (6.0.1)\n",
      "Requirement already satisfied: wcwidth in /home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages (from prettytable->pytorch-quantization==2.1.3) (0.2.13)\n",
      "Downloading pytorch_quantization-2.1.3-py3-none-any.whl (54 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m54.1/54.1 kB\u001b[0m \u001b[31m148.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading prettytable-3.10.0-py3-none-any.whl (28 kB)\n",
      "Downloading sphinx_glpi_theme-0.6-py2.py3-none-any.whl (4.2 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hInstalling collected packages: sphinx-glpi-theme, prettytable, absl-py, pytorch-quantization\n",
      "Successfully installed absl-py-2.1.0 prettytable-3.10.0 pytorch-quantization-2.1.3 sphinx-glpi-theme-0.6\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch-quantization==2.1.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Setup `gc` (garbage collector) and clear any `cache`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Start Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1. Training with `train.py` and argument `--model=yolov8n.pt`, `--epochs=0`, `--batch=16`, `--device=0` , `--qat`, `--data=coco128.yaml` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transferred 355/355 items from pretrained weights\n",
      "New https://pypi.org/project/ultralytics/8.2.51 available üòÉ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.2.48 üöÄ Python-3.9.19 torch-2.3.1+cu118 CUDA:0 (NVIDIA GeForce RTX 4070 SUPER, 12281MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n-modified.yaml, data=coco128.yaml, epochs=0, time=None, patience=50, batch=8, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=4, project=None, name=QAT_b8_e0_q40_relu6_rect, exist_ok=True, pretrained=yolov8n.pt, optimizer=auto, verbose=False, seed=0, deterministic=True, single_cls=False, rect=True, cos_lr=False, close_mosaic=0, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=None, overlap_mask=True, mask_ratio=4, dropout=0.0, qat=True, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=2.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/run/detect/QAT_b8_e0_q40_relu6_rect\n",
      "\u001b[34m\u001b[1mactivation:\u001b[0m nn.ReLU6()\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    897664  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          \n",
      "YOLOv8n-modified summary: 225 layers, 3157200 parameters, 3157184 gradients, 8.9 GFLOPs\n",
      "\n",
      "Transferred 355/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-q\u001b[0m\n",
      "WARNING ‚ö†Ô∏è 'rect=True' is incompatible with DataLoader shuffle, setting shuffle=False\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat\u001b[0m\n",
      "Plotting labels to /home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/run/detect/QAT_b8_e0_q40_relu6_rect/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.0001' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Add QuantConv to model.0.conv\n",
      "Add QuantConv to model.1.conv\n",
      "Add C2fQuantChunk to model.2\n",
      "Add QuantConv to model.2.cv1.conv\n",
      "Add QuantConv to model.2.cv2.conv\n",
      "Add QuantAdd to model.2.m.0\n",
      "Add QuantConv to model.2.m.0.cv1.conv\n",
      "Add QuantConv to model.2.m.0.cv2.conv\n",
      "Add QuantConv to model.3.conv\n",
      "Add C2fQuantChunk to model.4\n",
      "Add QuantConv to model.4.cv1.conv\n",
      "Add QuantConv to model.4.cv2.conv\n",
      "Add QuantAdd to model.4.m.0\n",
      "Add QuantConv to model.4.m.0.cv1.conv\n",
      "Add QuantConv to model.4.m.0.cv2.conv\n",
      "Add QuantAdd to model.4.m.1\n",
      "Add QuantConv to model.4.m.1.cv1.conv\n",
      "Add QuantConv to model.4.m.1.cv2.conv\n",
      "Add QuantConv to model.5.conv\n",
      "Add C2fQuantChunk to model.6\n",
      "Add QuantConv to model.6.cv1.conv\n",
      "Add QuantConv to model.6.cv2.conv\n",
      "Add QuantAdd to model.6.m.0\n",
      "Add QuantConv to model.6.m.0.cv1.conv\n",
      "Add QuantConv to model.6.m.0.cv2.conv\n",
      "Add QuantAdd to model.6.m.1\n",
      "Add QuantConv to model.6.m.1.cv1.conv\n",
      "Add QuantConv to model.6.m.1.cv2.conv\n",
      "Add QuantConv to model.7.conv\n",
      "Add C2fQuantChunk to model.8\n",
      "Add QuantConv to model.8.cv1.conv\n",
      "Add QuantConv to model.8.cv2.conv\n",
      "Add QuantAdd to model.8.m.0\n",
      "Add QuantConv to model.8.m.0.cv1.conv\n",
      "Add QuantConv to model.8.m.0.cv2.conv\n",
      "Add QuantConv to model.9.cv1.conv\n",
      "Add QuantConv to model.9.cv2.conv\n",
      "Add QuantUpsample to model.10\n",
      "Add QuantConcat to model.11\n",
      "Add C2fQuantChunk to model.12\n",
      "Add QuantConv to model.12.cv1.conv\n",
      "Add QuantConv to model.12.cv2.conv\n",
      "Add QuantConv to model.12.m.0.cv1.conv\n",
      "Add QuantConv to model.12.m.0.cv2.conv\n",
      "Add QuantUpsample to model.13\n",
      "Add QuantConcat to model.14\n",
      "Add C2fQuantChunk to model.15\n",
      "Add QuantConv to model.15.cv1.conv\n",
      "Add QuantConv to model.15.cv2.conv\n",
      "Add QuantConv to model.15.m.0.cv1.conv\n",
      "Add QuantConv to model.15.m.0.cv2.conv\n",
      "Add QuantConv to model.16.conv\n",
      "Add QuantConcat to model.17\n",
      "Add C2fQuantChunk to model.18\n",
      "Add QuantConv to model.18.cv1.conv\n",
      "Add QuantConv to model.18.cv2.conv\n",
      "Add QuantConv to model.18.m.0.cv1.conv\n",
      "Add QuantConv to model.18.m.0.cv2.conv\n",
      "Add QuantConv to model.19.conv\n",
      "Add QuantConcat to model.20\n",
      "Add C2fQuantChunk to model.21\n",
      "Add QuantConv to model.21.cv1.conv\n",
      "Add QuantConv to model.21.cv2.conv\n",
      "Add QuantConv to model.21.m.0.cv1.conv\n",
      "Add QuantConv to model.21.m.0.cv2.conv\n",
      "Add QuantConv to model.22.cv2.0.0.conv\n",
      "Add QuantConv to model.22.cv2.0.1.conv\n",
      "Add QuantConv to model.22.cv2.0.2\n",
      "Add QuantConv to model.22.cv2.1.0.conv\n",
      "Add QuantConv to model.22.cv2.1.1.conv\n",
      "Add QuantConv to model.22.cv2.1.2\n",
      "Add QuantConv to model.22.cv2.2.0.conv\n",
      "Add QuantConv to model.22.cv2.2.1.conv\n",
      "Add QuantConv to model.22.cv2.2.2\n",
      "Add QuantConv to model.22.cv3.0.0.conv\n",
      "Add QuantConv to model.22.cv3.0.1.conv\n",
      "Add QuantConv to model.22.cv3.0.2\n",
      "Add QuantConv to model.22.cv3.1.0.conv\n",
      "Add QuantConv to model.22.cv3.1.1.conv\n",
      "Add QuantConv to model.22.cv3.1.2\n",
      "Add QuantConv to model.22.cv3.2.0.conv\n",
      "Add QuantConv to model.22.cv3.2.1.conv\n",
      "Add QuantConv to model.22.cv3.2.2\n",
      "Add QuantConv to model.22.dfl.conv\n",
      "Collect stats for calibrating:   2%|‚ñè         | 16/1024 [00:05<05:34,  3.01it/s]\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0709 11:52:50.342481 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.342702 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.342860 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.342983 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.343116 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.343246 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.343379 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.343473 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.343592 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.343694 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.343804 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.343918 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.344043 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.344142 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.344253 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.344378 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.344495 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.344604 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.344709 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.344837 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.344934 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.345045 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.345140 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.345248 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.345365 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.345431 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.345522 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.345627 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.345731 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.345840 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.345929 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.346048 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.346152 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.346249 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.346359 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.346446 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.346545 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.346632 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.346728 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.346814 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.346930 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.347018 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.347114 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.347200 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.347292 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.347389 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.347483 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.347569 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.347666 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.347751 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.347860 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.347946 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.348038 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.348131 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.348217 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.348315 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.348417 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.348512 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.348599 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.348699 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.348787 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.348915 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.349002 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.349107 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.349194 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.349282 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.349443 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.349559 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.349685 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.349854 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.350022 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.350139 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.350260 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.350406 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.350525 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.350630 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.350719 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.350825 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.350937 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.351033 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.351118 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.351209 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.351298 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.351410 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.351496 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.351608 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.351711 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.351824 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.351944 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.352044 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.352149 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.352289 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.352416 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.352564 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.352674 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.352762 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.352902 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.353007 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.353118 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.353221 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.353357 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.353450 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.353592 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.353724 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.353822 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.353940 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.354033 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.354146 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.354234 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.354339 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.354427 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.354520 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.354604 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.354698 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.354794 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.354904 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.354990 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.355084 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.355169 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.355259 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.355385 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.355469 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.355564 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.355648 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.355740 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.355836 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.355933 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.356018 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.356112 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.356196 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.356288 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.356374 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.356467 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.356552 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.356646 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.356731 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.356822 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.356921 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.357017 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.357102 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.357196 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.357280 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.357374 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.357458 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.357552 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.357636 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.357730 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.357814 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.357919 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.358003 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.358095 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.358180 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.358273 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.358367 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.358458 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.358542 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.358634 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.358719 140712779694720 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0709 11:52:50.358939 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.359024 140712779694720 tensor_quantizer.py:239] Call .cuda() if running on GPU after loading calibrated amax.\n",
      "W0709 11:52:50.359158 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([16, 1, 1, 1]).\n",
      "W0709 11:52:50.359315 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.359501 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([32, 1, 1, 1]).\n",
      "W0709 11:52:50.359691 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.359848 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([32, 1, 1, 1]).\n",
      "W0709 11:52:50.359969 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.360085 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([32, 1, 1, 1]).\n",
      "W0709 11:52:50.360251 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.360384 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([16, 1, 1, 1]).\n",
      "W0709 11:52:50.360503 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.360615 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([16, 1, 1, 1]).\n",
      "W0709 11:52:50.360728 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.360849 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.360960 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.361101 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.361244 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0709 11:52:50.361407 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.361523 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0709 11:52:50.361668 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.361779 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0709 11:52:50.361965 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.362132 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([32, 1, 1, 1]).\n",
      "W0709 11:52:50.362267 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.362401 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([32, 1, 1, 1]).\n",
      "W0709 11:52:50.362522 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.362654 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.362778 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.362899 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([32, 1, 1, 1]).\n",
      "W0709 11:52:50.363011 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.363140 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([32, 1, 1, 1]).\n",
      "W0709 11:52:50.363281 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.363388 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.363516 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.363641 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.363755 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([128, 1, 1, 1]).\n",
      "W0709 11:52:50.363906 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.364023 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([128, 1, 1, 1]).\n",
      "W0709 11:52:50.364172 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.364282 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([128, 1, 1, 1]).\n",
      "W0709 11:52:50.364402 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.364511 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0709 11:52:50.364626 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.364734 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0709 11:52:50.364924 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.365108 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.365261 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.365455 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0709 11:52:50.365602 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.365734 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0709 11:52:50.365883 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.366003 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.366192 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.366415 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.366751 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([256, 1, 1, 1]).\n",
      "W0709 11:52:50.366937 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.367095 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([256, 1, 1, 1]).\n",
      "W0709 11:52:50.367534 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.367719 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([256, 1, 1, 1]).\n",
      "W0709 11:52:50.367964 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.368163 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([128, 1, 1, 1]).\n",
      "W0709 11:52:50.368512 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.368674 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([128, 1, 1, 1]).\n",
      "W0709 11:52:50.368820 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.368982 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.369120 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.369263 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.369422 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([128, 1, 1, 1]).\n",
      "W0709 11:52:50.369563 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.369679 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([256, 1, 1, 1]).\n",
      "W0709 11:52:50.369814 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.369952 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.370072 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.370201 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.370368 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([128, 1, 1, 1]).\n",
      "W0709 11:52:50.370508 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.370627 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([128, 1, 1, 1]).\n",
      "W0709 11:52:50.370810 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.371014 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0709 11:52:50.371210 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.371386 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0709 11:52:50.371507 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.371622 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.371737 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.371884 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.372029 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.372159 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0709 11:52:50.372284 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.372406 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0709 11:52:50.372547 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.372655 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([32, 1, 1, 1]).\n",
      "W0709 11:52:50.372802 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.372942 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([32, 1, 1, 1]).\n",
      "W0709 11:52:50.373075 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.373195 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.373325 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0709 11:52:50.373462 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.373577 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.373693 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.373805 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([128, 1, 1, 1]).\n",
      "W0709 11:52:50.373943 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.374050 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([128, 1, 1, 1]).\n",
      "W0709 11:52:50.374176 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.374300 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0709 11:52:50.374426 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.374545 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0709 11:52:50.374697 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.374846 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.374986 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([128, 1, 1, 1]).\n",
      "W0709 11:52:50.375160 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.375276 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.375409 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.375520 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([256, 1, 1, 1]).\n",
      "W0709 11:52:50.375636 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.375746 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([256, 1, 1, 1]).\n",
      "W0709 11:52:50.375884 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.375995 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([128, 1, 1, 1]).\n",
      "W0709 11:52:50.376128 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.376239 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([128, 1, 1, 1]).\n",
      "W0709 11:52:50.376371 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.376496 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.376616 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0709 11:52:50.376751 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.376873 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0709 11:52:50.376984 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.377089 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0709 11:52:50.377202 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.377309 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0709 11:52:50.377436 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.377543 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0709 11:52:50.377654 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.377759 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0709 11:52:50.377887 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.377993 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0709 11:52:50.378106 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.378212 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0709 11:52:50.378323 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.378444 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0709 11:52:50.378559 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.378666 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([80, 1, 1, 1]).\n",
      "W0709 11:52:50.378777 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.378939 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([80, 1, 1, 1]).\n",
      "W0709 11:52:50.379071 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.379196 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([80, 1, 1, 1]).\n",
      "W0709 11:52:50.379328 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.379469 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([80, 1, 1, 1]).\n",
      "W0709 11:52:50.379622 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.379749 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([80, 1, 1, 1]).\n",
      "W0709 11:52:50.379894 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.380020 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([80, 1, 1, 1]).\n",
      "W0709 11:52:50.380152 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.380283 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([80, 1, 1, 1]).\n",
      "W0709 11:52:50.380500 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.380611 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([80, 1, 1, 1]).\n",
      "W0709 11:52:50.380725 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.380849 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([80, 1, 1, 1]).\n",
      "W0709 11:52:50.380965 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0709 11:52:50.381072 140712779694720 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1m/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/run/detect/QAT_b8_e0_q40_relu6_rect\u001b[0m\n",
      "Starting training for 40 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       1/40      2.95G      1.886      3.772      1.679         37        448: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        128        929   0.000185    0.00522   0.000248   9.29e-05\n",
      "W0709 11:53:04.202853 140712779694720 tensor_quantizer.py:281] Use Pytorch's native experimental fake quantization.\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:284: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if amax.numel() == 1:\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:286: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  inputs, amax.item() / bound, 0,\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:292: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  quant_dim = list(amax.shape).index(list(amax_sequeeze.shape)[0])\n",
      "/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/ultralytics/nn/modules/head.py:92: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.dynamic or self.shape != shape:\n",
      "/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/ultralytics/utils/tal.py:299: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).\n",
      "  for i, stride in enumerate(strides):\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       2/40      2.42G      1.756      3.223      1.591         41        448: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        128        929    0.00111     0.0251    0.00374    0.00154\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:284: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if amax.numel() == 1:\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:286: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  inputs, amax.item() / bound, 0,\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:292: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  quant_dim = list(amax.shape).index(list(amax_sequeeze.shape)[0])\n",
      "/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/ultralytics/nn/modules/head.py:92: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.dynamic or self.shape != shape:\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       3/40      2.42G      1.685      2.996      1.566         35        448: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        128        929      0.071      0.111     0.0662     0.0302\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:284: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if amax.numel() == 1:\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:286: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  inputs, amax.item() / bound, 0,\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:292: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  quant_dim = list(amax.shape).index(list(amax_sequeeze.shape)[0])\n",
      "/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/ultralytics/nn/modules/head.py:92: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.dynamic or self.shape != shape:\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       4/40      2.42G      1.646      2.821      1.546         41        448: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        128        929     0.0642      0.318      0.177      0.116\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:284: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if amax.numel() == 1:\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:286: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  inputs, amax.item() / bound, 0,\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:292: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  quant_dim = list(amax.shape).index(list(amax_sequeeze.shape)[0])\n",
      "/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/ultralytics/nn/modules/head.py:92: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.dynamic or self.shape != shape:\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       5/40      2.42G      1.626      2.666      1.519         39        448: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        128        929     0.0722      0.504       0.31      0.211\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:284: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if amax.numel() == 1:\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:286: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  inputs, amax.item() / bound, 0,\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:292: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  quant_dim = list(amax.shape).index(list(amax_sequeeze.shape)[0])\n",
      "/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/ultralytics/nn/modules/head.py:92: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.dynamic or self.shape != shape:\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       6/40      2.42G      1.571      2.718        1.5         38        448: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        128        929       0.48      0.302      0.321      0.214\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:284: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if amax.numel() == 1:\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:286: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  inputs, amax.item() / bound, 0,\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:292: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  quant_dim = list(amax.shape).index(list(amax_sequeeze.shape)[0])\n",
      "/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/ultralytics/nn/modules/head.py:92: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.dynamic or self.shape != shape:\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       7/40      2.42G      1.567      2.564       1.49         41        448: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        128        929       0.65      0.227       0.33      0.221\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:284: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if amax.numel() == 1:\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:286: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  inputs, amax.item() / bound, 0,\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:292: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  quant_dim = list(amax.shape).index(list(amax_sequeeze.shape)[0])\n",
      "/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/ultralytics/nn/modules/head.py:92: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.dynamic or self.shape != shape:\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       8/40      2.42G      1.556      2.537      1.492         39        448: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        128        929      0.755      0.182       0.35      0.235\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:284: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if amax.numel() == 1:\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:286: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  inputs, amax.item() / bound, 0,\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:292: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  quant_dim = list(amax.shape).index(list(amax_sequeeze.shape)[0])\n",
      "/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/ultralytics/nn/modules/head.py:92: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.dynamic or self.shape != shape:\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       9/40      2.42G      1.537      2.517      1.454         38        448: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        128        929      0.782      0.176      0.357      0.233\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:284: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if amax.numel() == 1:\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:286: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  inputs, amax.item() / bound, 0,\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:292: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  quant_dim = list(amax.shape).index(list(amax_sequeeze.shape)[0])\n",
      "/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/ultralytics/nn/modules/head.py:92: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.dynamic or self.shape != shape:\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      10/40      2.42G      1.528      2.399      1.457         38        448: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        128        929      0.815      0.166      0.348      0.236\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:284: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if amax.numel() == 1:\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:286: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  inputs, amax.item() / bound, 0,\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:292: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  quant_dim = list(amax.shape).index(list(amax_sequeeze.shape)[0])\n",
      "/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/ultralytics/nn/modules/head.py:92: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.dynamic or self.shape != shape:\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      11/40      2.42G      1.529      2.328      1.454         39        448: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        128        929      0.793       0.18      0.353      0.239\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:284: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if amax.numel() == 1:\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:286: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  inputs, amax.item() / bound, 0,\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:292: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  quant_dim = list(amax.shape).index(list(amax_sequeeze.shape)[0])\n",
      "/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/ultralytics/nn/modules/head.py:92: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.dynamic or self.shape != shape:\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      12/40      2.42G      1.521      2.338      1.429         38        448: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        128        929      0.773      0.187      0.376      0.254\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:284: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if amax.numel() == 1:\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:286: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  inputs, amax.item() / bound, 0,\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:292: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  quant_dim = list(amax.shape).index(list(amax_sequeeze.shape)[0])\n",
      "/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/ultralytics/nn/modules/head.py:92: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.dynamic or self.shape != shape:\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      13/40      2.42G      1.478       2.31      1.446         37        448: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        128        929       0.78      0.198      0.371      0.254\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:284: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if amax.numel() == 1:\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:286: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  inputs, amax.item() / bound, 0,\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:292: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  quant_dim = list(amax.shape).index(list(amax_sequeeze.shape)[0])\n",
      "/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/ultralytics/nn/modules/head.py:92: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.dynamic or self.shape != shape:\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      14/40      2.42G      1.465      2.248      1.413         41        448: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        128        929      0.784      0.226       0.41      0.278\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:284: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if amax.numel() == 1:\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:286: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  inputs, amax.item() / bound, 0,\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:292: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  quant_dim = list(amax.shape).index(list(amax_sequeeze.shape)[0])\n",
      "/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/ultralytics/nn/modules/head.py:92: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.dynamic or self.shape != shape:\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      15/40      2.42G      1.458      2.235      1.427         36        448: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        128        929       0.79       0.23      0.417      0.283\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:284: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if amax.numel() == 1:\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:286: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  inputs, amax.item() / bound, 0,\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:292: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  quant_dim = list(amax.shape).index(list(amax_sequeeze.shape)[0])\n",
      "/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/ultralytics/nn/modules/head.py:92: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.dynamic or self.shape != shape:\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      16/40      2.42G      1.443      2.144      1.396         39        448: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        128        929      0.779      0.245      0.421      0.291\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:284: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if amax.numel() == 1:\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:286: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  inputs, amax.item() / bound, 0,\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:292: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  quant_dim = list(amax.shape).index(list(amax_sequeeze.shape)[0])\n",
      "/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/ultralytics/nn/modules/head.py:92: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.dynamic or self.shape != shape:\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      17/40      2.42G      1.422       2.11      1.386         41        448: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        128        929      0.775      0.256       0.43        0.3\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:284: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if amax.numel() == 1:\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:286: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  inputs, amax.item() / bound, 0,\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:292: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  quant_dim = list(amax.shape).index(list(amax_sequeeze.shape)[0])\n",
      "/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/ultralytics/nn/modules/head.py:92: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.dynamic or self.shape != shape:\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      18/40      2.42G      1.461      2.086      1.423         40        448: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        128        929      0.771      0.262      0.443      0.308\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:284: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if amax.numel() == 1:\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:286: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  inputs, amax.item() / bound, 0,\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:292: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  quant_dim = list(amax.shape).index(list(amax_sequeeze.shape)[0])\n",
      "/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/ultralytics/nn/modules/head.py:92: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.dynamic or self.shape != shape:\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      19/40      2.42G      1.457      2.158      1.414         35        448: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        128        929      0.773       0.27      0.462      0.318\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:284: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if amax.numel() == 1:\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:286: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  inputs, amax.item() / bound, 0,\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:292: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  quant_dim = list(amax.shape).index(list(amax_sequeeze.shape)[0])\n",
      "/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/ultralytics/nn/modules/head.py:92: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.dynamic or self.shape != shape:\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      20/40      2.42G      1.424      2.093      1.406         40        448: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        128        929      0.776      0.279      0.471      0.324\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:284: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if amax.numel() == 1:\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:286: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  inputs, amax.item() / bound, 0,\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:292: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  quant_dim = list(amax.shape).index(list(amax_sequeeze.shape)[0])\n",
      "/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/ultralytics/nn/modules/head.py:92: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.dynamic or self.shape != shape:\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      21/40      2.42G      1.394      2.012      1.366         39        448: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        128        929      0.774      0.288      0.468      0.322\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:284: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if amax.numel() == 1:\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:286: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  inputs, amax.item() / bound, 0,\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:292: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  quant_dim = list(amax.shape).index(list(amax_sequeeze.shape)[0])\n",
      "/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/ultralytics/nn/modules/head.py:92: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.dynamic or self.shape != shape:\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      22/40      2.42G      1.367      1.997      1.351         37        448: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        128        929      0.773      0.299      0.473      0.327\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:284: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if amax.numel() == 1:\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:286: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  inputs, amax.item() / bound, 0,\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:292: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  quant_dim = list(amax.shape).index(list(amax_sequeeze.shape)[0])\n",
      "/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/ultralytics/nn/modules/head.py:92: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.dynamic or self.shape != shape:\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      23/40      2.42G      1.401      1.962      1.348         41        448: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        128        929      0.755        0.3      0.476      0.329\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:284: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if amax.numel() == 1:\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:286: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  inputs, amax.item() / bound, 0,\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:292: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  quant_dim = list(amax.shape).index(list(amax_sequeeze.shape)[0])\n",
      "/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/ultralytics/nn/modules/head.py:92: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.dynamic or self.shape != shape:\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      24/40      2.42G      1.336      1.994       1.36         37        448: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        128        929      0.754      0.294      0.473      0.329\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:284: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if amax.numel() == 1:\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:286: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  inputs, amax.item() / bound, 0,\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:292: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  quant_dim = list(amax.shape).index(list(amax_sequeeze.shape)[0])\n",
      "/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/ultralytics/nn/modules/head.py:92: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.dynamic or self.shape != shape:\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      25/40      2.42G      1.391      1.946      1.367         41        448: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        128        929      0.751      0.302      0.477      0.332\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:284: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if amax.numel() == 1:\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:286: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  inputs, amax.item() / bound, 0,\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:292: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  quant_dim = list(amax.shape).index(list(amax_sequeeze.shape)[0])\n",
      "/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/ultralytics/nn/modules/head.py:92: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.dynamic or self.shape != shape:\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      26/40      2.42G      1.404      1.998      1.359         41        448: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        128        929      0.764      0.308      0.482      0.334\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:284: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if amax.numel() == 1:\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:286: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  inputs, amax.item() / bound, 0,\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:292: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  quant_dim = list(amax.shape).index(list(amax_sequeeze.shape)[0])\n",
      "/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/ultralytics/nn/modules/head.py:92: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.dynamic or self.shape != shape:\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      27/40      2.42G      1.346      1.932      1.363         41        448: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        128        929      0.756      0.302      0.488       0.34\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:284: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if amax.numel() == 1:\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:286: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  inputs, amax.item() / bound, 0,\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:292: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  quant_dim = list(amax.shape).index(list(amax_sequeeze.shape)[0])\n",
      "/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/ultralytics/nn/modules/head.py:92: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.dynamic or self.shape != shape:\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      28/40      2.42G      1.346      1.926      1.345         36        448: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        128        929      0.746        0.3      0.481      0.335\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:284: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if amax.numel() == 1:\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:286: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  inputs, amax.item() / bound, 0,\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:292: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  quant_dim = list(amax.shape).index(list(amax_sequeeze.shape)[0])\n",
      "/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/ultralytics/nn/modules/head.py:92: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.dynamic or self.shape != shape:\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      29/40      2.42G      1.341      1.893      1.331         41        448: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        128        929      0.738      0.306      0.479      0.334\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:284: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if amax.numel() == 1:\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:286: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  inputs, amax.item() / bound, 0,\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:292: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  quant_dim = list(amax.shape).index(list(amax_sequeeze.shape)[0])\n",
      "/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/ultralytics/nn/modules/head.py:92: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.dynamic or self.shape != shape:\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      30/40      2.42G      1.355      1.902       1.35         41        448: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        128        929      0.737      0.314      0.482       0.34\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:284: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if amax.numel() == 1:\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:286: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  inputs, amax.item() / bound, 0,\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:292: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  quant_dim = list(amax.shape).index(list(amax_sequeeze.shape)[0])\n",
      "/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/ultralytics/nn/modules/head.py:92: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.dynamic or self.shape != shape:\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      31/40      2.42G      1.357       1.89       1.36         37        448: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        128        929      0.735      0.317      0.486      0.342\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:284: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if amax.numel() == 1:\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:286: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  inputs, amax.item() / bound, 0,\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:292: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  quant_dim = list(amax.shape).index(list(amax_sequeeze.shape)[0])\n",
      "/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/ultralytics/nn/modules/head.py:92: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.dynamic or self.shape != shape:\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      32/40      2.42G      1.333      1.828      1.318         41        448: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        128        929      0.735      0.318      0.477      0.342\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:284: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if amax.numel() == 1:\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:286: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  inputs, amax.item() / bound, 0,\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:292: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  quant_dim = list(amax.shape).index(list(amax_sequeeze.shape)[0])\n",
      "/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/ultralytics/nn/modules/head.py:92: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.dynamic or self.shape != shape:\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      33/40      2.42G      1.345      1.914      1.351         37        448: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        128        929      0.729      0.319      0.483      0.343\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:284: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if amax.numel() == 1:\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:286: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  inputs, amax.item() / bound, 0,\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:292: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  quant_dim = list(amax.shape).index(list(amax_sequeeze.shape)[0])\n",
      "/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/ultralytics/nn/modules/head.py:92: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.dynamic or self.shape != shape:\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      34/40      2.42G      1.368      1.874      1.345         40        448: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        128        929       0.73      0.323       0.48      0.338\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:284: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if amax.numel() == 1:\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:286: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  inputs, amax.item() / bound, 0,\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:292: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  quant_dim = list(amax.shape).index(list(amax_sequeeze.shape)[0])\n",
      "/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/ultralytics/nn/modules/head.py:92: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.dynamic or self.shape != shape:\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      35/40      2.42G      1.322      1.931      1.328         38        448: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        128        929      0.744      0.322      0.479      0.336\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:284: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if amax.numel() == 1:\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:286: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  inputs, amax.item() / bound, 0,\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:292: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  quant_dim = list(amax.shape).index(list(amax_sequeeze.shape)[0])\n",
      "/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/ultralytics/nn/modules/head.py:92: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.dynamic or self.shape != shape:\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      36/40      2.42G      1.343      1.844      1.338         37        448: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        128        929      0.736      0.322       0.47      0.334\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:284: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if amax.numel() == 1:\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:286: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  inputs, amax.item() / bound, 0,\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:292: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  quant_dim = list(amax.shape).index(list(amax_sequeeze.shape)[0])\n",
      "/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/ultralytics/nn/modules/head.py:92: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.dynamic or self.shape != shape:\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      37/40      2.42G      1.331      1.881      1.333         38        448: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        128        929      0.738      0.327       0.48      0.336\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:284: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if amax.numel() == 1:\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:286: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  inputs, amax.item() / bound, 0,\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:292: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  quant_dim = list(amax.shape).index(list(amax_sequeeze.shape)[0])\n",
      "/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/ultralytics/nn/modules/head.py:92: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.dynamic or self.shape != shape:\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      38/40      2.42G      1.319      1.865       1.31         39        448: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        128        929       0.74      0.333      0.474      0.337\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:284: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if amax.numel() == 1:\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:286: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  inputs, amax.item() / bound, 0,\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:292: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  quant_dim = list(amax.shape).index(list(amax_sequeeze.shape)[0])\n",
      "/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/ultralytics/nn/modules/head.py:92: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.dynamic or self.shape != shape:\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      39/40      2.42G      1.314      1.857      1.321         40        448: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        128        929      0.735      0.328      0.474      0.339\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:284: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if amax.numel() == 1:\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:286: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  inputs, amax.item() / bound, 0,\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:292: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  quant_dim = list(amax.shape).index(list(amax_sequeeze.shape)[0])\n",
      "/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/ultralytics/nn/modules/head.py:92: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.dynamic or self.shape != shape:\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      40/40      2.42G       1.35      1.864      1.329         37        448: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        128        929      0.737      0.325      0.474      0.339\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:284: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if amax.numel() == 1:\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:286: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  inputs, amax.item() / bound, 0,\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:292: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  quant_dim = list(amax.shape).index(list(amax_sequeeze.shape)[0])\n",
      "/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/ultralytics/nn/modules/head.py:92: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.dynamic or self.shape != shape:\n",
      "\n",
      "40 epochs completed in 0.162 hours.\n",
      "Optimizer stripped from /home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/run/detect/QAT_b8_e0_q40_relu6_rect/weights/last_qat.pt, 6.5MB\n",
      "Optimizer stripped from /home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/run/detect/QAT_b8_e0_q40_relu6_rect/weights/best_qat.pt, 6.5MB\n",
      "\n",
      "Validating /home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/run/detect/QAT_b8_e0_q40_relu6_rect/weights/best_qat.pt...\n",
      "Ultralytics YOLOv8.2.48 üöÄ Python-3.9.19 torch-2.3.1+cu118 CUDA:0 (NVIDIA GeForce RTX 4070 SUPER, 12281MiB)\n",
      "YOLOv8n-modified summary (fused): 282 layers, 3151904 parameters, 0 gradients, 0.2 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        128        929      0.746      0.319       0.48      0.346\n",
      "Speed: 0.8ms preprocess, 17.9ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "Results saved to \u001b[1m/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/run/detect/QAT_b8_e0_q40_relu6_rect\u001b[0m\n",
      "Ultralytics YOLOv8.2.48 üöÄ Python-3.9.19 torch-2.3.1+cu118 CUDA:0 (NVIDIA GeForce RTX 4070 SUPER, 12281MiB)\n",
      "YOLOv8n-modified summary (fused): 282 layers, 3151904 parameters, 0 gradients, 0.2 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat\u001b[0m\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        128        929      0.732      0.309      0.469      0.336\n",
      "Speed: 1.3ms preprocess, 33.5ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
      "Results saved to \u001b[1m/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/run/detect/QAT_b8_e0_q40_relu6_rect\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python train.py --pretrained=yolov8n.pt --data=coco128.yaml --model=yolov8n-modified.yaml --epochs=0 --batch=8 --device=0 --qat --workers=4 --device=0 --name=QAT_b8_e0_q40_relu6_rect --exist_ok --rect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transferred 355/355 items from pretrained weights\n",
      "New https://pypi.org/project/ultralytics/8.2.50 available üòÉ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.2.48 üöÄ Python-3.9.19 torch-2.3.1+cu118 CUDA:0 (NVIDIA GeForce RTX 4070 SUPER, 12281MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n-modified.yaml, data=/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/datasets/line-detection-qat/cc50/data.yaml, epochs=100, time=None, patience=50, batch=8, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=4, project=None, name=QAT_b16_e100_q40_silu_rect_line_detection_50cc, exist_ok=True, pretrained=yolov8n.pt, optimizer=auto, verbose=False, seed=0, deterministic=True, single_cls=True, rect=True, cos_lr=False, close_mosaic=0, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=None, overlap_mask=True, mask_ratio=4, dropout=0.0, qat=True, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=2.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/run/detect/QAT_b16_e100_q40_silu_rect_line_detection_50cc\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\u001b[34m\u001b[1mactivation:\u001b[0m nn.SiLU()\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "YOLOv8n-modified summary: 225 layers, 3011043 parameters, 3011027 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-q\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/datasets/line-detection-qat/cc50/train/labels.cache\n",
      "WARNING ‚ö†Ô∏è 'rect=True' is incompatible with DataLoader shuffle, setting shuffle=False\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/datasets/line-detection-qat/cc50/valid/labels.cache\n",
      "Plotting labels to /home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/run/detect/QAT_b16_e100_q40_silu_rect_line_detection_50cc/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1m/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/run/detect/QAT_b16_e100_q40_silu_rect_line_detection_50cc\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      1/100      1.29G      1.627      1.484       1.14        176        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.684       0.78      0.768      0.255\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      2/100      1.28G      1.659      3.183      1.039        184        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.771       0.82      0.867      0.406\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      3/100      1.28G      1.699      2.842      1.084        199        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.704      0.704      0.753      0.362\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      4/100      1.28G      1.714       2.49      1.083        196        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.591      0.771      0.634      0.343\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      5/100      1.28G      1.742      2.111      1.086        197        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.709      0.762      0.774      0.341\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      6/100      1.28G      1.762      1.835      1.116        192        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.712      0.817      0.818      0.388\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      7/100      1.28G      1.596      1.682      1.048        191        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.742      0.813      0.831       0.42\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      8/100      1.28G      1.646      1.949      1.028        188        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.678      0.852      0.721      0.391\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      9/100      1.28G      1.618      1.812      1.035        197        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.783      0.849      0.861      0.463\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     10/100      1.28G      1.605      1.771      1.052        181        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.851       0.84      0.912      0.479\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     11/100      1.28G      1.458      1.347      1.005        176        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.869      0.893      0.942      0.559\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     12/100      1.28G      1.522      1.438      1.004        200        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.835      0.877      0.928      0.553\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     13/100      1.28G      1.499      1.153     0.9974        181        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.854      0.912      0.933      0.539\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     14/100      1.28G      1.439      1.123      1.002        196        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.812      0.864      0.913      0.534\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     15/100      1.28G      1.363      1.031     0.9654        199        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.868      0.909      0.944       0.56\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     16/100      1.27G      1.356      1.022     0.9752        193        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.914      0.913      0.969      0.612\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     17/100      1.28G       1.34     0.9534     0.9596        185        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.892      0.925      0.956      0.601\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     18/100      1.28G       1.32     0.9099       0.97        190        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.932      0.928      0.974      0.591\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     19/100      1.27G       1.31     0.8945     0.9529        200        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795       0.93      0.927      0.969      0.624\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     20/100      1.27G      1.236     0.8392     0.9488        196        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.934      0.928      0.972      0.632\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     21/100      1.28G      1.288     0.8997     0.9556        171        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.923      0.892      0.971      0.637\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     22/100      1.28G      1.236     0.8869      0.953        177        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.928      0.936      0.972      0.646\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     23/100      1.27G      1.238     0.8573     0.9447        183        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.934      0.932      0.979      0.662\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     24/100      1.28G      1.201     0.8097     0.9334        200        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.896      0.916      0.951      0.624\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     25/100      1.28G      1.194     0.8063     0.9397        190        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.928      0.945      0.979      0.629\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     26/100      1.28G      1.227     0.7981     0.9385        192        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.898      0.931      0.961       0.58\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     27/100      1.27G      1.212     0.7941     0.9439        196        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.944      0.894      0.976      0.625\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     28/100      1.28G      1.184     0.7936     0.9284        189        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.873      0.931      0.934      0.509\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     29/100      1.28G      1.234     0.8709     0.9412        200        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.956      0.908      0.975       0.61\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     30/100      1.28G      1.221     0.8111     0.9395        187        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.952      0.948      0.983       0.57\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     31/100      1.27G      1.232     0.7866     0.9355        172        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795       0.93      0.934      0.973      0.659\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     32/100      1.27G      1.159     0.7486     0.9235        191        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.949      0.958      0.984      0.596\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     33/100      1.28G      1.235     0.7532     0.9274        199        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.943      0.956      0.982      0.657\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     34/100      1.28G      1.121     0.7145     0.9169        192        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.965      0.952      0.988      0.693\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     35/100      1.27G      1.131     0.7018     0.9436        197        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.922      0.947      0.977      0.588\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     36/100      1.28G      1.163     0.7641     0.9298        190        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795       0.95      0.926      0.973      0.562\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     37/100      1.28G      1.251     0.8304     0.9189        200        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.912      0.925      0.961      0.576\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     38/100      1.28G      1.135     0.8241     0.9139        190        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.963      0.953      0.988      0.657\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     39/100      1.27G      1.088     0.7137      0.901        193        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.912      0.941       0.96      0.635\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     40/100      1.27G      1.091     0.6817     0.8969        188        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.945       0.93      0.978      0.609\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     41/100      1.28G      1.125     0.7155        0.9        174        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.911      0.941      0.966      0.549\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     42/100      1.28G      1.183     0.7638     0.9131        179        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.923      0.951       0.98      0.655\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     43/100      1.28G      1.118     0.6893     0.9076        186        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.958      0.927      0.983      0.693\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     44/100      1.28G      1.203     0.7082     0.9259        189        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795       0.93       0.94      0.975      0.616\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     45/100      1.28G      1.373     0.7739      0.941        193        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.932      0.903      0.974       0.59\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     46/100      1.28G      1.181     0.7225     0.9322        194        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.946       0.95      0.976      0.666\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     47/100      1.27G       1.22     0.7243     0.9663        192        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.942      0.909      0.977      0.644\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     48/100      1.27G      1.098     0.6859     0.9454        192        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.905      0.932      0.937      0.639\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     49/100      1.28G      1.122     0.7026     0.9163        188        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.962      0.949      0.987      0.686\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     50/100      1.28G      1.108     0.6727     0.9259        192        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.938       0.94       0.98      0.624\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     51/100      1.27G      1.127     0.6697     0.9184        191        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.963      0.956      0.988      0.693\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     52/100      1.28G      1.113     0.6491     0.9178        187        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.957      0.959      0.987      0.691\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     53/100      1.28G      1.128     0.6653     0.9361        200        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.951      0.922       0.98      0.692\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     54/100      1.28G      1.106     0.6509     0.9172        200        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.955      0.936      0.982      0.675\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     55/100      1.27G      1.069     0.6345     0.9167        191        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.973      0.953      0.989       0.69\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     56/100      1.27G      1.199     0.6502     0.9178        183        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.958      0.933      0.983      0.622\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     57/100      1.28G      1.138     0.6432     0.9012        193        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.967      0.963       0.99      0.737\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     58/100      1.28G      1.095     0.6359      0.891        195        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.961      0.949      0.986      0.705\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     59/100      1.27G      1.013     0.6001     0.8837        183        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.967      0.958      0.988      0.729\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     60/100      1.28G     0.9794     0.5906     0.8786        183        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.971      0.957      0.988      0.699\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     61/100      1.28G      1.002     0.6087     0.8836        194        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.974      0.968      0.989      0.718\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     62/100      1.28G      1.017     0.6089      0.878        184        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.959      0.947      0.985      0.726\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     63/100      1.27G      1.018     0.6114     0.8863        195        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.972      0.965      0.991      0.694\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     64/100      1.27G      1.028      0.598     0.8775        200        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795       0.97      0.935      0.982        0.7\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     65/100      1.28G      1.108     0.6297     0.8906        188        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.979      0.961       0.99      0.723\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     66/100      1.28G      1.046     0.5941     0.8688        196        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.974      0.967       0.99      0.739\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     67/100      1.27G     0.9883     0.5729     0.8633        200        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.985      0.967      0.991      0.747\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     68/100      1.27G     0.9895     0.5595      0.862        197        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.977      0.957      0.988      0.738\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     69/100      1.28G     0.9384     0.5528     0.8606        197        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.977      0.962      0.989      0.715\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     70/100      1.28G     0.9941     0.5852     0.8682        176        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.981       0.96      0.988      0.746\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     71/100      1.27G     0.9562     0.5555     0.8664        192        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.985      0.971      0.991      0.754\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     72/100      1.27G     0.9694     0.5598     0.8654        192        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.984       0.97      0.992      0.734\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     73/100      1.28G      0.977     0.5617     0.8685        186        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.986      0.961      0.989      0.746\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     74/100      1.27G      1.015     0.5481     0.8823        200        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.983      0.959      0.989      0.741\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     75/100      1.27G     0.9542     0.5497      0.876        182        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.989      0.967      0.992      0.776\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     76/100      1.27G      0.918     0.5335     0.8592        191        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.986      0.971      0.992       0.77\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     77/100      1.28G     0.9232     0.5274     0.8592        197        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.982      0.966      0.992      0.739\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     78/100      1.28G     0.9292     0.5328      0.858        178        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.985      0.962      0.991      0.776\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     79/100      1.27G     0.9573     0.5413     0.8596        194        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.981      0.955      0.987      0.712\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     80/100      1.28G     0.9521     0.5542     0.8568        190        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.981      0.966      0.991      0.774\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     81/100      1.28G     0.8739     0.5098      0.849        186        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.988      0.969      0.991      0.771\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     82/100      1.28G     0.8986     0.5212     0.8492        192        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.982       0.91      0.983      0.737\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     83/100      1.27G     0.8974     0.5117     0.8513        189        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.988      0.928      0.988      0.789\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     84/100      1.28G     0.8938     0.5118     0.8471        194        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.984      0.966      0.992      0.783\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     85/100      1.28G     0.8665     0.5016     0.8482        188        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.986      0.965       0.99      0.782\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     86/100      1.28G     0.8472     0.4941     0.8506        194        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.983      0.964       0.99      0.767\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     87/100      1.27G     0.8562     0.4936     0.8487        188        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.989      0.966      0.991      0.788\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     88/100      1.27G     0.8441     0.4857     0.8459        191        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.989      0.969      0.992      0.794\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     89/100      1.27G     0.8447     0.4923     0.8472        189        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.989      0.966      0.991      0.794\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     90/100      1.28G     0.8654     0.4925      0.848        188        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.988      0.969      0.992      0.794\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     91/100      1.27G     0.8422     0.4814     0.8483        171        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.986      0.968      0.991      0.788\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     92/100      1.28G      0.839     0.4822      0.846        195        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795       0.99       0.97      0.992      0.794\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     93/100      1.28G     0.8297     0.4772     0.8423        198        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795       0.99      0.961      0.991      0.794\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     94/100      1.27G     0.8484       0.48     0.8393        200        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.988      0.963      0.991      0.759\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     95/100      1.27G     0.8321     0.4757     0.8412        180        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.989      0.969      0.992      0.801\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     96/100      1.27G     0.8143     0.4704     0.8408        192        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.986      0.966      0.991      0.803\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     97/100      1.27G     0.8138     0.4672     0.8372        176        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.988       0.97      0.992        0.8\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     98/100      1.28G     0.8062     0.4667     0.8376        200        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.991      0.964      0.991        0.8\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     99/100      1.27G      0.794      0.461     0.8351        190        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.987       0.97      0.992      0.802\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    100/100      1.28G     0.7841     0.4566     0.8375        193        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.992      0.967      0.992      0.805\n",
      "\n",
      "100 epochs completed in 0.612 hours.\n",
      "Optimizer stripped from /home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/run/detect/QAT_b16_e100_q40_silu_rect_line_detection_50cc/weights/last.pt, 6.2MB\n",
      "Optimizer stripped from /home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/run/detect/QAT_b16_e100_q40_silu_rect_line_detection_50cc/weights/best.pt, 6.2MB\n",
      "\n",
      "Validating /home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/run/detect/QAT_b16_e100_q40_silu_rect_line_detection_50cc/weights/best.pt...\n",
      "Ultralytics YOLOv8.2.48 üöÄ Python-3.9.19 torch-2.3.1+cu118 CUDA:0 (NVIDIA GeForce RTX 4070 SUPER, 12281MiB)\n",
      "YOLOv8n-modified summary (fused): 168 layers, 3005843 parameters, 0 gradients, 8.1 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.992      0.967      0.992      0.805\n",
      "Speed: 1.1ms preprocess, 4.1ms inference, 0.0ms loss, 2.6ms postprocess per image\n",
      "Results saved to \u001b[1m/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/run/detect/QAT_b16_e100_q40_silu_rect_line_detection_50cc\u001b[0m\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-q\u001b[0m\n",
      "WARNING ‚ö†Ô∏è 'rect=True' is incompatible with DataLoader shuffle, setting shuffle=False\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat\u001b[0m\n",
      "Plotting labels to /home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/run/detect/QAT_b16_e100_q40_silu_rect_line_detection_50cc/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.0001' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Add QuantConv to model.0.conv\n",
      "Add QuantConv to model.1.conv\n",
      "Add C2fQuantChunk to model.2\n",
      "Add QuantConv to model.2.cv1.conv\n",
      "Add QuantConv to model.2.cv2.conv\n",
      "Add QuantAdd to model.2.m.0\n",
      "Add QuantConv to model.2.m.0.cv1.conv\n",
      "Add QuantConv to model.2.m.0.cv2.conv\n",
      "Add QuantConv to model.3.conv\n",
      "Add C2fQuantChunk to model.4\n",
      "Add QuantConv to model.4.cv1.conv\n",
      "Add QuantConv to model.4.cv2.conv\n",
      "Add QuantAdd to model.4.m.0\n",
      "Add QuantConv to model.4.m.0.cv1.conv\n",
      "Add QuantConv to model.4.m.0.cv2.conv\n",
      "Add QuantAdd to model.4.m.1\n",
      "Add QuantConv to model.4.m.1.cv1.conv\n",
      "Add QuantConv to model.4.m.1.cv2.conv\n",
      "Add QuantConv to model.5.conv\n",
      "Add C2fQuantChunk to model.6\n",
      "Add QuantConv to model.6.cv1.conv\n",
      "Add QuantConv to model.6.cv2.conv\n",
      "Add QuantAdd to model.6.m.0\n",
      "Add QuantConv to model.6.m.0.cv1.conv\n",
      "Add QuantConv to model.6.m.0.cv2.conv\n",
      "Add QuantAdd to model.6.m.1\n",
      "Add QuantConv to model.6.m.1.cv1.conv\n",
      "Add QuantConv to model.6.m.1.cv2.conv\n",
      "Add QuantConv to model.7.conv\n",
      "Add C2fQuantChunk to model.8\n",
      "Add QuantConv to model.8.cv1.conv\n",
      "Add QuantConv to model.8.cv2.conv\n",
      "Add QuantAdd to model.8.m.0\n",
      "Add QuantConv to model.8.m.0.cv1.conv\n",
      "Add QuantConv to model.8.m.0.cv2.conv\n",
      "Add QuantConv to model.9.cv1.conv\n",
      "Add QuantConv to model.9.cv2.conv\n",
      "Add QuantUpsample to model.10\n",
      "Add QuantConcat to model.11\n",
      "Add C2fQuantChunk to model.12\n",
      "Add QuantConv to model.12.cv1.conv\n",
      "Add QuantConv to model.12.cv2.conv\n",
      "Add QuantConv to model.12.m.0.cv1.conv\n",
      "Add QuantConv to model.12.m.0.cv2.conv\n",
      "Add QuantUpsample to model.13\n",
      "Add QuantConcat to model.14\n",
      "Add C2fQuantChunk to model.15\n",
      "Add QuantConv to model.15.cv1.conv\n",
      "Add QuantConv to model.15.cv2.conv\n",
      "Add QuantConv to model.15.m.0.cv1.conv\n",
      "Add QuantConv to model.15.m.0.cv2.conv\n",
      "Add QuantConv to model.16.conv\n",
      "Add QuantConcat to model.17\n",
      "Add C2fQuantChunk to model.18\n",
      "Add QuantConv to model.18.cv1.conv\n",
      "Add QuantConv to model.18.cv2.conv\n",
      "Add QuantConv to model.18.m.0.cv1.conv\n",
      "Add QuantConv to model.18.m.0.cv2.conv\n",
      "Add QuantConv to model.19.conv\n",
      "Add QuantConcat to model.20\n",
      "Add C2fQuantChunk to model.21\n",
      "Add QuantConv to model.21.cv1.conv\n",
      "Add QuantConv to model.21.cv2.conv\n",
      "Add QuantConv to model.21.m.0.cv1.conv\n",
      "Add QuantConv to model.21.m.0.cv2.conv\n",
      "Add QuantConv to model.22.cv2.0.0.conv\n",
      "Add QuantConv to model.22.cv2.0.1.conv\n",
      "Add QuantConv to model.22.cv2.0.2\n",
      "Add QuantConv to model.22.cv2.1.0.conv\n",
      "Add QuantConv to model.22.cv2.1.1.conv\n",
      "Add QuantConv to model.22.cv2.1.2\n",
      "Add QuantConv to model.22.cv2.2.0.conv\n",
      "Add QuantConv to model.22.cv2.2.1.conv\n",
      "Add QuantConv to model.22.cv2.2.2\n",
      "Add QuantConv to model.22.cv3.0.0.conv\n",
      "Add QuantConv to model.22.cv3.0.1.conv\n",
      "Add QuantConv to model.22.cv3.0.2\n",
      "Add QuantConv to model.22.cv3.1.0.conv\n",
      "Add QuantConv to model.22.cv3.1.1.conv\n",
      "Add QuantConv to model.22.cv3.1.2\n",
      "Add QuantConv to model.22.cv3.2.0.conv\n",
      "Add QuantConv to model.22.cv3.2.1.conv\n",
      "Add QuantConv to model.22.cv3.2.2\n",
      "Add QuantConv to model.22.dfl.conv\n",
      "Collect stats for calibrating:  12%|‚ñà        | 119/1024 [00:27<03:29,  4.32it/s]\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0708 16:21:53.567394 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.567678 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.567815 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.567906 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.568025 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.568137 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.568248 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.568346 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.568461 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.568575 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.568685 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.568782 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.568887 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.568985 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.569237 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.569403 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.569568 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.569708 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.569812 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.569983 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.570094 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.570199 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.570449 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.570977 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.571286 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.571471 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.571615 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.571771 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.571902 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.572067 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.572205 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.572353 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.572490 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.572663 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.572834 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.572974 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.573193 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.573386 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.573591 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.573731 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.573893 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.574007 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.574162 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.574279 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.574403 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.574517 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.574660 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.574777 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.574913 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.575018 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.575159 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.575265 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.575383 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.575528 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.575639 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.575769 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.575868 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.575974 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.576086 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.576197 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.576295 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.576401 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.576498 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.576607 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.576704 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.576794 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.576900 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.577012 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.577130 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.577228 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.577336 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.577439 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.577536 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.577660 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.577757 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.577862 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.577959 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.578087 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.578185 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.578291 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.578387 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.578490 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.578621 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.578722 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.578819 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.578923 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.579019 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.579226 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.579325 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.579431 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.579520 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.579646 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.579734 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.579826 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.579921 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.580008 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.580162 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.580269 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.580395 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.580492 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.580630 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.580727 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.580862 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.580959 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.581102 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.581211 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.581332 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.581444 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.581539 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.581650 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.581737 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.581834 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.581925 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.582020 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.582122 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.582224 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.582313 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.582410 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.582497 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.582600 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.582702 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.582790 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.582888 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.582976 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.583087 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.583175 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.583271 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.583359 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.583456 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.583544 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.583656 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.583742 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.583839 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.583927 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.584023 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.584125 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.584223 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.584311 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.584409 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.584496 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.584602 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.584690 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.584785 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.584872 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.584969 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.585073 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.585171 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.585259 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.585354 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.585441 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.585536 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.585670 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.585768 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.585856 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.585951 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.586039 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.586149 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.586236 140268255187584 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0708 16:21:53.586426 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.586513 140268255187584 tensor_quantizer.py:239] Call .cuda() if running on GPU after loading calibrated amax.\n",
      "W0708 16:21:53.586658 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([16, 1, 1, 1]).\n",
      "W0708 16:21:53.586786 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.586903 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([32, 1, 1, 1]).\n",
      "W0708 16:21:53.587043 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.587231 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([32, 1, 1, 1]).\n",
      "W0708 16:21:53.587407 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.587575 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([32, 1, 1, 1]).\n",
      "W0708 16:21:53.587832 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.588016 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([16, 1, 1, 1]).\n",
      "W0708 16:21:53.588156 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.588273 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([16, 1, 1, 1]).\n",
      "W0708 16:21:53.588393 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.588514 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.588680 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.588838 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.589022 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0708 16:21:53.589187 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.589325 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0708 16:21:53.589523 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.589808 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0708 16:21:53.589977 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.590117 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([32, 1, 1, 1]).\n",
      "W0708 16:21:53.590261 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.590395 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([32, 1, 1, 1]).\n",
      "W0708 16:21:53.590520 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.590654 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.590780 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.590913 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([32, 1, 1, 1]).\n",
      "W0708 16:21:53.591042 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.591181 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([32, 1, 1, 1]).\n",
      "W0708 16:21:53.591308 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.591427 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.591564 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.591690 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.591814 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([128, 1, 1, 1]).\n",
      "W0708 16:21:53.591986 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.592119 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([128, 1, 1, 1]).\n",
      "W0708 16:21:53.592258 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.592372 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([128, 1, 1, 1]).\n",
      "W0708 16:21:53.592498 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.592668 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0708 16:21:53.592824 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.592962 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0708 16:21:53.593144 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.593306 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.593453 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.593647 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0708 16:21:53.593787 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.593935 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0708 16:21:53.594095 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.594216 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.594352 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.594501 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.594727 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([256, 1, 1, 1]).\n",
      "W0708 16:21:53.594874 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.595003 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([256, 1, 1, 1]).\n",
      "W0708 16:21:53.595163 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.595294 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([256, 1, 1, 1]).\n",
      "W0708 16:21:53.595434 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.595583 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([128, 1, 1, 1]).\n",
      "W0708 16:21:53.595720 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.595839 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([128, 1, 1, 1]).\n",
      "W0708 16:21:53.595979 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.596121 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.596249 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.596384 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.596512 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([128, 1, 1, 1]).\n",
      "W0708 16:21:53.596655 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.596782 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([256, 1, 1, 1]).\n",
      "W0708 16:21:53.596917 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.597092 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.597221 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.597357 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.597488 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([128, 1, 1, 1]).\n",
      "W0708 16:21:53.597641 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.597772 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([128, 1, 1, 1]).\n",
      "W0708 16:21:53.597913 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.598047 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0708 16:21:53.598204 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.598334 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0708 16:21:53.598466 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.598619 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.598751 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.598876 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.599011 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.599150 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0708 16:21:53.599279 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.599391 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0708 16:21:53.599514 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.599654 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([32, 1, 1, 1]).\n",
      "W0708 16:21:53.599770 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.599880 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([32, 1, 1, 1]).\n",
      "W0708 16:21:53.599993 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.600124 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.600234 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0708 16:21:53.600371 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.600489 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.600670 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.600807 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([128, 1, 1, 1]).\n",
      "W0708 16:21:53.600936 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.601082 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([128, 1, 1, 1]).\n",
      "W0708 16:21:53.601232 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.601347 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0708 16:21:53.601472 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.601624 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0708 16:21:53.601760 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.601906 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.602075 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([128, 1, 1, 1]).\n",
      "W0708 16:21:53.602196 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.602323 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.602442 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.602596 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([256, 1, 1, 1]).\n",
      "W0708 16:21:53.602726 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.602849 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([256, 1, 1, 1]).\n",
      "W0708 16:21:53.602971 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.603106 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([128, 1, 1, 1]).\n",
      "W0708 16:21:53.603225 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.603373 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([128, 1, 1, 1]).\n",
      "W0708 16:21:53.603511 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.603686 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.603849 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0708 16:21:53.604034 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.604222 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0708 16:21:53.604399 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.604597 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0708 16:21:53.604786 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.604909 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0708 16:21:53.605091 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.605247 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0708 16:21:53.605440 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.605641 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0708 16:21:53.605778 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.605895 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0708 16:21:53.606084 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.606240 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0708 16:21:53.606401 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.606587 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0708 16:21:53.606727 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.606887 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0708 16:21:53.607149 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.607330 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0708 16:21:53.607496 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.607661 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.607823 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.607981 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0708 16:21:53.608173 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.608397 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0708 16:21:53.608712 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.608898 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.609107 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.609272 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0708 16:21:53.609438 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.609600 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0708 16:21:53.609752 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.609870 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.610018 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0708 16:21:53.610279 140268255187584 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1m/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/run/detect/QAT_b16_e100_q40_silu_rect_line_detection_50cc\u001b[0m\n",
      "Starting training for 40 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       1/40      2.94G      1.104     0.6368     0.9014        184        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.953      0.958      0.985      0.693\n",
      "W0708 16:22:55.012975 140268255187584 tensor_quantizer.py:281] Use Pytorch's native experimental fake quantization.\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:284: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if amax.numel() == 1:\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:286: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  inputs, amax.item() / bound, 0,\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:292: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  quant_dim = list(amax.shape).index(list(amax_sequeeze.shape)[0])\n",
      "/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/ultralytics/nn/modules/head.py:92: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.dynamic or self.shape != shape:\n",
      "/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/ultralytics/utils/tal.py:299: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).\n",
      "  for i, stride in enumerate(strides):\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       2/40      2.44G      1.072     0.6746     0.9006        199        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.893      0.907      0.931      0.619\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:284: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if amax.numel() == 1:\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:286: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  inputs, amax.item() / bound, 0,\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:292: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  quant_dim = list(amax.shape).index(list(amax_sequeeze.shape)[0])\n",
      "/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/ultralytics/nn/modules/head.py:92: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.dynamic or self.shape != shape:\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       3/40      2.45G      1.092     0.7558     0.9031        196        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.908      0.946      0.958      0.652\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:284: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if amax.numel() == 1:\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:286: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  inputs, amax.item() / bound, 0,\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:292: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  quant_dim = list(amax.shape).index(list(amax_sequeeze.shape)[0])\n",
      "/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/ultralytics/nn/modules/head.py:92: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.dynamic or self.shape != shape:\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       4/40      2.59G      1.089     0.7152     0.9097        197        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.927      0.917       0.97      0.679\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:284: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if amax.numel() == 1:\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:286: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  inputs, amax.item() / bound, 0,\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:292: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  quant_dim = list(amax.shape).index(list(amax_sequeeze.shape)[0])\n",
      "/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/ultralytics/nn/modules/head.py:92: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.dynamic or self.shape != shape:\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       5/40      2.45G      1.084     0.6696     0.8999        192        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.921       0.92      0.973      0.689\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:284: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if amax.numel() == 1:\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:286: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  inputs, amax.item() / bound, 0,\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:292: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  quant_dim = list(amax.shape).index(list(amax_sequeeze.shape)[0])\n",
      "/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/ultralytics/nn/modules/head.py:92: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.dynamic or self.shape != shape:\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       6/40      2.58G      1.097     0.6914     0.9096        191        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.955      0.927       0.98      0.654\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:284: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if amax.numel() == 1:\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:286: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  inputs, amax.item() / bound, 0,\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:292: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  quant_dim = list(amax.shape).index(list(amax_sequeeze.shape)[0])\n",
      "/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/ultralytics/nn/modules/head.py:92: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.dynamic or self.shape != shape:\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       7/40      2.58G      1.071     0.6622     0.9045        188        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.954      0.964      0.986      0.711\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:284: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if amax.numel() == 1:\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:286: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  inputs, amax.item() / bound, 0,\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:292: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  quant_dim = list(amax.shape).index(list(amax_sequeeze.shape)[0])\n",
      "/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/ultralytics/nn/modules/head.py:92: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.dynamic or self.shape != shape:\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       8/40      2.45G      1.148     0.6671     0.9286        197        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.966      0.963      0.987      0.641\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:284: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if amax.numel() == 1:\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:286: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  inputs, amax.item() / bound, 0,\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:292: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  quant_dim = list(amax.shape).index(list(amax_sequeeze.shape)[0])\n",
      "/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/ultralytics/nn/modules/head.py:92: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.dynamic or self.shape != shape:\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       9/40      2.45G       1.06     0.6311       0.91        181        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.971      0.957      0.989      0.721\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:284: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if amax.numel() == 1:\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:286: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  inputs, amax.item() / bound, 0,\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:292: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  quant_dim = list(amax.shape).index(list(amax_sequeeze.shape)[0])\n",
      "/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/ultralytics/nn/modules/head.py:92: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.dynamic or self.shape != shape:\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      10/40      2.45G      1.061     0.6412     0.8998        176        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.962      0.938      0.987      0.723\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:284: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if amax.numel() == 1:\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:286: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  inputs, amax.item() / bound, 0,\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:292: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  quant_dim = list(amax.shape).index(list(amax_sequeeze.shape)[0])\n",
      "/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/ultralytics/nn/modules/head.py:92: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.dynamic or self.shape != shape:\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      11/40      2.45G      1.065      0.627     0.9178        200        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.967      0.931      0.982      0.683\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:284: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if amax.numel() == 1:\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:286: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  inputs, amax.item() / bound, 0,\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:292: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  quant_dim = list(amax.shape).index(list(amax_sequeeze.shape)[0])\n",
      "/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/ultralytics/nn/modules/head.py:92: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.dynamic or self.shape != shape:\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      12/40      2.59G      1.087     0.6504     0.9018        181        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.973      0.956       0.99      0.606\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:284: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if amax.numel() == 1:\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:286: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  inputs, amax.item() / bound, 0,\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:292: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  quant_dim = list(amax.shape).index(list(amax_sequeeze.shape)[0])\n",
      "/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/ultralytics/nn/modules/head.py:92: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.dynamic or self.shape != shape:\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      13/40      2.58G      1.054     0.6508     0.9032        196        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.927      0.949      0.979      0.705\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:284: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if amax.numel() == 1:\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:286: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  inputs, amax.item() / bound, 0,\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:292: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  quant_dim = list(amax.shape).index(list(amax_sequeeze.shape)[0])\n",
      "/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/ultralytics/nn/modules/head.py:92: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.dynamic or self.shape != shape:\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      14/40      2.45G      1.088     0.6739     0.9092        199        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.954      0.913      0.974      0.703\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:284: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if amax.numel() == 1:\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:286: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  inputs, amax.item() / bound, 0,\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:292: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  quant_dim = list(amax.shape).index(list(amax_sequeeze.shape)[0])\n",
      "/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/ultralytics/nn/modules/head.py:92: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.dynamic or self.shape != shape:\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      15/40      2.45G      1.039     0.6513     0.9034        193        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.905      0.918      0.959      0.676\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:284: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if amax.numel() == 1:\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:286: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  inputs, amax.item() / bound, 0,\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:292: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  quant_dim = list(amax.shape).index(list(amax_sequeeze.shape)[0])\n",
      "/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/ultralytics/nn/modules/head.py:92: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.dynamic or self.shape != shape:\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      16/40      2.45G      1.149     0.7556     0.9219        185        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.898      0.933      0.964      0.693\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:284: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if amax.numel() == 1:\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:286: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  inputs, amax.item() / bound, 0,\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:292: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  quant_dim = list(amax.shape).index(list(amax_sequeeze.shape)[0])\n",
      "/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/ultralytics/nn/modules/head.py:92: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.dynamic or self.shape != shape:\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      17/40      2.45G      1.017     0.6391     0.9012        190        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.952      0.972      0.989       0.74\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:284: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if amax.numel() == 1:\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:286: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  inputs, amax.item() / bound, 0,\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:292: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  quant_dim = list(amax.shape).index(list(amax_sequeeze.shape)[0])\n",
      "/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/ultralytics/nn/modules/head.py:92: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.dynamic or self.shape != shape:\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      18/40      2.58G       1.03     0.6036     0.8829        200        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.925      0.946      0.973      0.639\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:284: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if amax.numel() == 1:\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:286: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  inputs, amax.item() / bound, 0,\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:292: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  quant_dim = list(amax.shape).index(list(amax_sequeeze.shape)[0])\n",
      "/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/ultralytics/nn/modules/head.py:92: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.dynamic or self.shape != shape:\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      19/40      2.59G      1.137     0.6684     0.8955        196        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.935      0.936      0.978      0.679\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:284: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if amax.numel() == 1:\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:286: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  inputs, amax.item() / bound, 0,\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:292: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  quant_dim = list(amax.shape).index(list(amax_sequeeze.shape)[0])\n",
      "/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/ultralytics/nn/modules/head.py:92: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.dynamic or self.shape != shape:\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      20/40      2.45G      1.099     0.6194     0.8884        171        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.968      0.975       0.99      0.697\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:284: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if amax.numel() == 1:\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:286: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  inputs, amax.item() / bound, 0,\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:292: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  quant_dim = list(amax.shape).index(list(amax_sequeeze.shape)[0])\n",
      "/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/ultralytics/nn/modules/head.py:92: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.dynamic or self.shape != shape:\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      21/40      2.45G      1.002     0.5984     0.8891        177        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.963      0.969      0.988      0.731\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:284: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if amax.numel() == 1:\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:286: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  inputs, amax.item() / bound, 0,\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:292: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  quant_dim = list(amax.shape).index(list(amax_sequeeze.shape)[0])\n",
      "/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/ultralytics/nn/modules/head.py:92: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.dynamic or self.shape != shape:\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      22/40      2.45G      1.008     0.5784     0.8889        183        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.967      0.956      0.987      0.675\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:284: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if amax.numel() == 1:\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:286: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  inputs, amax.item() / bound, 0,\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:292: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  quant_dim = list(amax.shape).index(list(amax_sequeeze.shape)[0])\n",
      "/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/ultralytics/nn/modules/head.py:92: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.dynamic or self.shape != shape:\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      23/40      2.45G      1.052      0.624     0.8906        200        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.962      0.951      0.985      0.742\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:284: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if amax.numel() == 1:\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:286: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  inputs, amax.item() / bound, 0,\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:292: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  quant_dim = list(amax.shape).index(list(amax_sequeeze.shape)[0])\n",
      "/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/ultralytics/nn/modules/head.py:92: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.dynamic or self.shape != shape:\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      24/40      2.45G      1.006     0.5921     0.8899        190        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.966      0.922      0.984      0.692\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:284: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if amax.numel() == 1:\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:286: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  inputs, amax.item() / bound, 0,\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:292: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  quant_dim = list(amax.shape).index(list(amax_sequeeze.shape)[0])\n",
      "/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/ultralytics/nn/modules/head.py:92: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.dynamic or self.shape != shape:\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      25/40      2.45G      1.056     0.5898     0.8985        192        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795       0.96      0.961      0.987      0.721\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:284: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if amax.numel() == 1:\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:286: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  inputs, amax.item() / bound, 0,\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:292: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  quant_dim = list(amax.shape).index(list(amax_sequeeze.shape)[0])\n",
      "/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/ultralytics/nn/modules/head.py:92: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.dynamic or self.shape != shape:\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      26/40      2.45G      1.037     0.5774     0.8952        196        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.985      0.969      0.991       0.75\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:284: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if amax.numel() == 1:\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:286: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  inputs, amax.item() / bound, 0,\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:292: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  quant_dim = list(amax.shape).index(list(amax_sequeeze.shape)[0])\n",
      "/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/ultralytics/nn/modules/head.py:92: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.dynamic or self.shape != shape:\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      27/40      2.45G      1.023     0.5802     0.8845        189        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.986      0.969      0.991      0.766\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:284: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if amax.numel() == 1:\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:286: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  inputs, amax.item() / bound, 0,\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:292: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  quant_dim = list(amax.shape).index(list(amax_sequeeze.shape)[0])\n",
      "/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/ultralytics/nn/modules/head.py:92: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.dynamic or self.shape != shape:\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      28/40      2.45G     0.9475     0.5292     0.8743        200        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795       0.99      0.966      0.991      0.764\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:284: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if amax.numel() == 1:\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:286: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  inputs, amax.item() / bound, 0,\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:292: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  quant_dim = list(amax.shape).index(list(amax_sequeeze.shape)[0])\n",
      "/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/ultralytics/nn/modules/head.py:92: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.dynamic or self.shape != shape:\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      29/40      2.45G      0.895     0.5165     0.8751        187        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.991      0.971      0.993      0.788\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:284: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if amax.numel() == 1:\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:286: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  inputs, amax.item() / bound, 0,\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:292: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  quant_dim = list(amax.shape).index(list(amax_sequeeze.shape)[0])\n",
      "/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/ultralytics/nn/modules/head.py:92: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.dynamic or self.shape != shape:\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      30/40      2.58G     0.8818     0.5053     0.8678        172        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.991      0.967      0.992       0.79\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:284: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if amax.numel() == 1:\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:286: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  inputs, amax.item() / bound, 0,\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:292: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  quant_dim = list(amax.shape).index(list(amax_sequeeze.shape)[0])\n",
      "/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/ultralytics/nn/modules/head.py:92: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.dynamic or self.shape != shape:\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      31/40      2.58G      0.863     0.4999     0.8587        191        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.993      0.967      0.991      0.784\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:284: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if amax.numel() == 1:\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:286: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  inputs, amax.item() / bound, 0,\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:292: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  quant_dim = list(amax.shape).index(list(amax_sequeeze.shape)[0])\n",
      "/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/ultralytics/nn/modules/head.py:92: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.dynamic or self.shape != shape:\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      32/40      2.45G     0.8845     0.5028     0.8568        199        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795       0.99       0.97      0.992       0.79\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:284: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if amax.numel() == 1:\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:286: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  inputs, amax.item() / bound, 0,\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:292: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  quant_dim = list(amax.shape).index(list(amax_sequeeze.shape)[0])\n",
      "/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/ultralytics/nn/modules/head.py:92: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.dynamic or self.shape != shape:\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      33/40      2.45G     0.8461     0.4907     0.8514        192        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795       0.99      0.967      0.992      0.801\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:284: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if amax.numel() == 1:\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:286: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  inputs, amax.item() / bound, 0,\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:292: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  quant_dim = list(amax.shape).index(list(amax_sequeeze.shape)[0])\n",
      "/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/ultralytics/nn/modules/head.py:92: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.dynamic or self.shape != shape:\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      34/40      2.45G     0.8389     0.4855      0.853        197        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.992       0.97      0.992      0.801\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:284: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if amax.numel() == 1:\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:286: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  inputs, amax.item() / bound, 0,\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:292: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  quant_dim = list(amax.shape).index(list(amax_sequeeze.shape)[0])\n",
      "/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/ultralytics/nn/modules/head.py:92: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.dynamic or self.shape != shape:\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      35/40      2.45G     0.8276     0.4779     0.8472        190        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.992      0.969      0.993      0.805\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:284: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if amax.numel() == 1:\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:286: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  inputs, amax.item() / bound, 0,\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:292: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  quant_dim = list(amax.shape).index(list(amax_sequeeze.shape)[0])\n",
      "/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/ultralytics/nn/modules/head.py:92: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.dynamic or self.shape != shape:\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      36/40      2.59G     0.8235     0.4823     0.8453        200        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.993       0.97      0.993      0.803\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:284: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if amax.numel() == 1:\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:286: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  inputs, amax.item() / bound, 0,\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:292: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  quant_dim = list(amax.shape).index(list(amax_sequeeze.shape)[0])\n",
      "/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/ultralytics/nn/modules/head.py:92: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.dynamic or self.shape != shape:\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      37/40      2.58G     0.8157     0.4804     0.8428        190        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.996      0.965      0.993       0.81\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:284: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if amax.numel() == 1:\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:286: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  inputs, amax.item() / bound, 0,\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:292: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  quant_dim = list(amax.shape).index(list(amax_sequeeze.shape)[0])\n",
      "/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/ultralytics/nn/modules/head.py:92: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.dynamic or self.shape != shape:\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      38/40      2.45G     0.8043     0.4718     0.8456        193        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.996      0.968      0.992      0.809\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:284: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if amax.numel() == 1:\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:286: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  inputs, amax.item() / bound, 0,\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:292: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  quant_dim = list(amax.shape).index(list(amax_sequeeze.shape)[0])\n",
      "/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/ultralytics/nn/modules/head.py:92: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.dynamic or self.shape != shape:\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      39/40      2.45G     0.8086     0.4702     0.8429        188        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.996      0.966      0.992      0.808\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:284: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if amax.numel() == 1:\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:286: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  inputs, amax.item() / bound, 0,\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:292: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  quant_dim = list(amax.shape).index(list(amax_sequeeze.shape)[0])\n",
      "/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/ultralytics/nn/modules/head.py:92: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.dynamic or self.shape != shape:\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      40/40      2.45G     0.7956     0.4674     0.8407        174        224: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.995      0.967      0.993      0.807\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:284: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if amax.numel() == 1:\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:286: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  inputs, amax.item() / bound, 0,\n",
      "/home/jeffrymahbuubi/Syringe-Detection/env/ultralytics-qat/lib/python3.9/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:292: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  quant_dim = list(amax.shape).index(list(amax_sequeeze.shape)[0])\n",
      "/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/ultralytics/nn/modules/head.py:92: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.dynamic or self.shape != shape:\n",
      "\n",
      "40 epochs completed in 0.399 hours.\n",
      "Optimizer stripped from /home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/run/detect/QAT_b16_e100_q40_silu_rect_line_detection_50cc/weights/last_qat.pt, 6.2MB\n",
      "Optimizer stripped from /home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/run/detect/QAT_b16_e100_q40_silu_rect_line_detection_50cc/weights/best_qat.pt, 6.2MB\n",
      "\n",
      "Validating /home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/run/detect/QAT_b16_e100_q40_silu_rect_line_detection_50cc/weights/best_qat.pt...\n",
      "Ultralytics YOLOv8.2.48 üöÄ Python-3.9.19 torch-2.3.1+cu118 CUDA:0 (NVIDIA GeForce RTX 4070 SUPER, 12281MiB)\n",
      "YOLOv8n-modified summary (fused): 282 layers, 3005843 parameters, 0 gradients, 0.1 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.992      0.969      0.993      0.807\n",
      "Speed: 0.8ms preprocess, 16.6ms inference, 0.0ms loss, 6.5ms postprocess per image\n",
      "Results saved to \u001b[1m/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/run/detect/QAT_b16_e100_q40_silu_rect_line_detection_50cc\u001b[0m\n",
      "Ultralytics YOLOv8.2.48 üöÄ Python-3.9.19 torch-2.3.1+cu118 CUDA:0 (NVIDIA GeForce RTX 4070 SUPER, 12281MiB)\n",
      "YOLOv8n-modified summary (fused): 282 layers, 3005843 parameters, 0 gradients, 0.1 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat\u001b[0m\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        118       2795      0.993      0.968      0.992      0.805\n",
      "Speed: 1.3ms preprocess, 41.2ms inference, 0.0ms loss, 1.7ms postprocess per image\n",
      "Results saved to \u001b[1m/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/run/detect/QAT_b16_e100_q40_silu_rect_line_detection_50cc\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python train.py --pretrained=yolov8n.pt --data=/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/datasets/line-detection-qat/cc50/data.yaml --model=yolov8n-modified.yaml --epochs=100 --batch=8 --device=0 --qat --workers=4 --device=0 --name=QAT_b16_e100_q40_silu_rect_line_detection_50cc --exist_ok --rect --single_cls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Experiment Summary\n",
    "\n",
    "- Thursday, 4 July 2024\n",
    "    - Epoch = 100\n",
    "    - Batch = 8\n",
    "    - Activation: \n",
    "        - `ReLU`\n",
    "            - mAP50, \n",
    "                - Original = 0.644\n",
    "                - Fine-Tuning with QAT = 0.641\n",
    "        - `SiLU`\n",
    "            - mAP50, \n",
    "                - Original = 0.710\n",
    "                - Fine-Tuning with QAT = 0.717\n",
    "    - Parameter\n",
    "        - `--rect` = False\n",
    "\n",
    "- Friday, 5 July 2024\n",
    "    - **Experiment 1**: \n",
    "        - Epoch = 100\n",
    "        - Batch = 8\n",
    "        - Activation: \n",
    "            - `SiLU`\n",
    "                - mAP50, \n",
    "                    - Original = 0.63\n",
    "                    - Fine-Tuning with QAT = 0.68\n",
    "        - Parameter\n",
    "            - `--rect` = True\n",
    "    - **Experiment 2**: \n",
    "        - Epoch = 200\n",
    "        - Batch = 8\n",
    "        - Activation: \n",
    "            - `SiLU`\n",
    "                - mAP50, \n",
    "                    - Original = 0.814\n",
    "                    - Fine-Tuning with QAT = 0.877 \n",
    "        - Parameter: \n",
    "            - `--rect` = True\n",
    "- Sunday, 7 July 2024\n",
    "    - **Rotation Detection**\n",
    "        - Epoch = 200\n",
    "        - Epoch-QAT = 20\n",
    "        - Batch = 8\n",
    "        - Activation: \n",
    "            - `SiLu`\n",
    "                - mAP50, \n",
    "                    - Original = 0.922\n",
    "                    - Fine-Tuning with QAT = 0.993 \n",
    "                - mAP50-95,\n",
    "                    - Original = 0.855\n",
    "                    - Fine-Tuning with QAT = 0.827\n",
    "        - Parameter:\n",
    "            - `--rect` = True\n",
    "    - **Syringe Detection**\n",
    "        - Epoch = 100\n",
    "        - Epoch-QAT = 40\n",
    "        - Batch = 8\n",
    "        - Activation:\n",
    "            - `SiLU`\n",
    "                - mAP50, \n",
    "                    - Original = 0.99\n",
    "                    - Fine-Tuning with QAT = 0.98 \n",
    "        - Parameter:\n",
    "            - `--rect` = True\n",
    "- Tuesday, 9 July 2024\n",
    "    - **Experiment 3**:\n",
    "        - Epoch = 200\n",
    "        - Epoch-QAT = 40\n",
    "        - Batch = 8\n",
    "        - Activation:\n",
    "            - `ReLU`,\n",
    "                - mAP50, \n",
    "                    - Original = 0.76 \n",
    "                    - Fine-Tuning with QAT = 0.87\n",
    "                - mAP50-95,\n",
    "                    - Original = 0.58\n",
    "                    - Fine-Tuning with QAT = 0.67\n",
    "        - Parameter:\n",
    "            - `--rect` = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['epoch', 'train/box_loss', 'train/cls_loss', 'train/dfl_loss',\n",
      "       'metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)',\n",
      "       'metrics/mAP50-95(B)', 'val/box_loss', 'val/cls_loss', 'val/dfl_loss',\n",
      "       'lr/pg0', 'lr/pg1', 'lr/pg2'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the data\n",
    "file_path = '/home/jeffrymahbuubi/Syringe-Detection/compression/ultralytics-qat-jeffry/run/detect/QAT_b16_e100_silu/results.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Clean column names by stripping whitespace\n",
    "data.columns = data.columns.str.strip()\n",
    "\n",
    "# Print cleaned column names to verify\n",
    "print(data.columns)\n",
    "\n",
    "# Extract the relevant columns\n",
    "epochs = data['epoch']\n",
    "map50_95 = data['metrics/mAP50-95(B)']\n",
    "\n",
    "# Plot the data\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot epochs below 101\n",
    "plt.plot(epochs[epochs <= 101], map50_95[epochs <= 101], marker='o', linestyle='-', color='b', label='Epoch <= 101 (Before QAT)')\n",
    "\n",
    "# Plot epochs above 101\n",
    "plt.plot(epochs[epochs > 101], map50_95[epochs > 101], marker='o', linestyle='-', color='r', label='Epoch > 101 (QAT Calibration)')\n",
    "\n",
    "# Add vertical line at epoch 101\n",
    "plt.axvline(x=101, color='k', linestyle='--', label='Transition Epoch 100 to 101')\n",
    "\n",
    "# Add titles and labels\n",
    "plt.title('mAP50-95(B) over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('mAP50-95(B)')\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ultralytics-qat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
